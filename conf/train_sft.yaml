sft:
  # source → task builders
  build:
    input_globs:
      - "data/canonical/canonical*.jsonl"
    out_jsonl: "out/sft/tasks.sft.jsonl"
    max_tasks:
      drug_label: 20000
      trial: 10000
      article: 10000
    min_section_chars: 120
    languages: ["en", "ar"]

  templates:
    persona: "doctor"          # "patient" | "doctor" | "pharmacist"
    enforce_citations: true
    otc_first: true

  data:
    train_path: "out/sft/tasks.sft.jsonl"
    max_seq_len: 1024          # ↓ lowered for CPU safety (use 512 if still tight)
    batch_size: 2              # ↓ lowered for CPU safety (use 1 if still tight)
    grad_accum: 1
    shuffle_buffer: 4000

  optimization:
    lr: 2.0e-5
    weight_decay: 0.05
    epochs: 1
    warmup_ratio: 0.06
    betas: [0.9, 0.95]
    amp: false                 # CPU run; AMP off; auto-enabled if you switch to CUDA code path later
    max_grad_norm: 1.0
    seed: 1337

  model:
    spm_model: "out/tokenizer/orph_spm.model"
    special_tokens: ["<pad>", "<s>", "</s>", "<unk>", "<triage>", "<referral>", "<cite>", "<arabic>", "<english>"]
    ckpt_in: "out/text_orphgpt/best.pt"
    ckpt_out_dir: "out/sft_orphgpt"
    keep_last_n: 3
